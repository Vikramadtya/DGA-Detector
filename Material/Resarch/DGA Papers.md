# DGA Papers

[toc]

## Keywords

- **Domain fluxing** is a technique for keeping a malicious botnet in operation by constantly changing the **domain** name of the botnet owner's Command and Control (C&C) server.
- **Second-level domain** refers to the substring of a domain name consisting of all the characters after the second-last dot before the public suffix. The substring between the last and second-last dots before the public suffix will be called the 2nd-level string, and its length the 2-length. For instance, both `s1.s2.example.com` and  `example.co.uk` have 2nd-level string example  and 2-length 7.

## Paper I - Finding Domain-Generation Algorithms by Looking at Length Distributions - 2014 

### Introduction

In domain fluxing, an infected machine periodically uses a seed and a domain generation algorithm (DGA) to automatically generate a large batch of domain names, and does a Domain Name Service (DNS) query to discover the domains’ IP addresses.

> The seed may be time-independent, or may depend on the current time or other time-varying public information such as top Twitter trends.

#### Communication With C&C

The command-and-control server contacts an infected machine by registering and using one of the generated domain names. If this domain is blacklisted, it can move to another of the generated domains. If a machine can be detected querying malware DGA domains, it may be possible to disinfect or quarantine it before the infection produces any symptoms.

#### Usual Approach Of Detection 

- To use machine learning to build a classifier based on features of DGA domain names or of queries for them. ==This approach only detects DGAs for which samples are available==. There is therefore a need to identify previously-unknown DGAs.
- DGAs can be determined from captured malware code, or by capturing the DNS traffic of a machine infected with malware that uses a new DGA.
- look for domain names that are not human-readable or human-understandable.
- look for **clusters of similar domains being queried by multiple clients**. This only ==catches infections in their later stages, when they have spread to several clients==. ==Combine this with other approaches, so that if a DGA is not detected early it may be detected later on.==

> However, some DGAs are designed to produce human-readable domain names.  Moreover, some benign domain names are not obviously human-understandable.

#### Idea

To look for clients querying domains with an unusual distribution of 2-lengths. procedure described can only detect DGAs that are used for second-level domain fluxing, and which generate batches of domains for which the 2-length distribution is unusual.

==Once domains from a new malware DGA have been detected, they can be used to train a classifier so that this DGA can be detected in the future.==

#### Privacy Consideration

Reason for identifying clients based on very limited information about the domain names is that this allows for greater privacy protection.

The pseudonymization of the domains preserves the public suffix and the 2-length, but may not preserve any other features.  Non-pseudonymized domains need only be examined for the candidates that have been identified as having unusual 2-length distributions, and the non-pseudonymized version of a candidate IP address need not be revealed until it has been confirmed that it is infected and action is needed to remedy this.

#### Procedure

##### 1. Convert upper-case letters to lower case

Convert upper-case letters in the second-level domain names to lower case.

==Doing this conversion is standard practice when searching for malware domains in DNS data, as the DNS service is caseinvariant==, 

> It ensured that client IP addresses making many queries of the same domain with different capitalization as a **defence against DNS spoofing would not appear to query many different domains with the same 2-length**.

##### 2. Delete entries with invalid suffixes

Second-level domains with invalid public suffixes were deleted. 

> Malware DGAs need to generate domains with valid public suffixes, so the second- level domains considered in the search for DGAs can be restricted to these.

##### 3. Delete repeatedly queried in a time slot

The data entries for domains with second-level domains that were queried more than 50 times in total in the appropriate time slot were also deleted. These ==are unlikely to be generated by a DGA used for second-level domain fluxing, unless many machines in the network have been compromised by the same malware and are querying the same domain.==

> it was useful to treat candidates that queried Chinese-language web sites separately, because the 2-lengths for Chinese-language web sites tend to be shorter than average, as a result of practices for representing Chinese- language domain names in Latin alphabet letters and numbers.

##### 4. Average

The **average 2-length distributions of (non-deleted) domain names queried by candidates in the two classes were calculated**, with each candidate in the class being weighted equally in the average.

##### 5. Distance 

For each candidate, the distance was calculated between the 2-length distribution during the time slot for domains queried by that candidate and the average distribution for either non-Chinese-speaking or Chinese-speaking candidates, candidates, depending on how the candidate was classified. The distance function used was the standard statistical distance function over a finite alphabet
$$
D(X,Y) = \frac{1}{2}|X_{(i)} - Y_{(i)}|
$$


where the sum is over all 2-length values $i$,  $X_{(i)}$ is the probability of $i$ in distribution $X$ and $Y_{(i)}$ the probability of $i$ in distribution $Y$.

##### 6. Anomaly

Find candidates for which the distance from the average was anomalously large.

##### 7.  Query the Anomaly 

For each of the candidates with anomalous 2-length distributions, DNS queries were made ten of the second-level domains that they queried in the time slot.If 6 or more of these queries resulted in the answer that the domain did not exist, the candidate was counted as an identified candidate. 

> most malware DGA domains have no DNS registration.

Some machine-learning techniques use the frequencies of different suffixes as one of their indicators to identify domains from known DGAs . These frequencies can be different in different batches, including batches queried by different clients on the same day.

if the underlying suffix distribution differs between batches, it seems that the DGA effectively uses the seed to determine an ordering of the suffixes, and chooses the suffix for a generated domain with a probability determined by this ordering.

Just as the suffix distributions may vary between different batches of the same DGA, so may the character and bigram distributions.

The procedure is only designed to detect second-level domain fluxing, but it might be possible to extend it to detect fluxing at a higher level by considering looking for unusual distributions of the lengths of higher-level strings.



The identification of Chinese- speaking candidates could be made more accurate by considering only country-code top-level domains rather than all 2-letter top-level domains - some misclassified candidates queried many domains with top-level domain cc or vn.



The check may eliminate some candidates that are in fact querying DGA domains. In particular, it will do so if most of these domains have been sinkholed,  that is, registered by others to prevent their use by the malware owner.

sensible for the check to count domains that resolve to a known sinkhole IP address as though they had no DNS registration.

It would be useful to automatically compare the features of domains queried by a reported candidate to known DGAs, to see whether the DGA is already known.



In order to be used in practice, the procedure needs to be integrated with network security tools and systems. Once DGAs have been identified, there also need to be processes to develop recognizers for domains produced by the DGAs, to identify infected clients in the network, and to remediate the associated problems.

## Paper II - From Throw-Away Traffic to Bots: Detecting the Rise of DGA-Based Malware - 2012

Many botnet detection systems employ a blacklist of known command and control (C&C) domains to detect bots and block their traffic. such a botnet detection approach is static because the blacklist is updated only after running an external (and often manual) process of domain discovery. 

> Employing domain generation algorithms (DGAs) to dynamically produce a large number of random domain names and select a small subset for actual C&C use

If we ==know how a domain generation algorithm works, we can generate the domains ahead of time and still identify and block botnet C&C traffic==. The existing solutions are largely based on reverse engineering of the bot malware executables, which is not always feasible.

Insight is that ==most of the DGA-generated (random) domains that a bot queries would result in Non-Existent Domain (NXDomain) responses, and that bots from the same botnet (with the same DGA algorithm) would generate similar NXDomain traffic==.

##### Approach

Uses a combination of clustering and classification algorithms. The clustering algorithm clusters domains based on the similarity in the make-ups of domain names as well as the groups of machines that queried these domains. The classification algorithm is used to assign the generated clusters to mod- els of known DGAs. If a cluster cannot be assigned to a known model, then a new model is produced, indicating a new DGA variant or family.

### Introduction

#### Botnet

Botnets are groups of malware-compromised machines, or bots, that can be remotely controlled by an attacker (the botmaster) through a command and control (C&C) communication channel.

##### Communication Technique

Each bot **periodically executes a domain generation algorithm (DGA) that, given a random seed (e.g., the current date), produces a list of candidate C&C domains**. The bot then attempts to re- solve these domain names by sending DNS queries un- til one of the domains resolves to the IP address of a C&C server. This strategy provides a remarkable level of agility because even if one or more C&C domain names or IP addresses are identified and taken down, the *bots will eventually get the IP address of the relocated C&C server via DNS queries* to the next set of automatically generated domains.

#### Reason for focusing on NXDomains

The focus on NXDomains is motivated by the fact that modern DGA- bots tend to query large sets of domain names among which relatively few successfully resolve to the IP address of the C&C server.

#### Intuition 

Multiple hosts may be compromised with the same DGA-bots. Therefore, each of these compromised assets will generate several DNS queries resulting in NXDomains, and a subset of these NXDomains will likely be queried by more than one compromised machine.

#### Proposed Solution - Pleiades

Pleiades is placed “below” the local recursive DNS (RDNS) server or at the edge of a network to mon- itor DNS query/response messages from/to the machines within the network. Specifically, ==Pleiades analyzes DNS queries for domain names that result in Name Error responses==.

Pleiades searches for relatively large clusters of NXDomains that 

1. have similar syntactic features, 
2.  are queried by multiple potentially compromised machines during a given epoch. 

When Pleiades finds a cluster of NXDomains, it ==applies statistical learning techniques to build a model of the DGA==.  

###### Purpose Of Statistical Learning

To detect future compromised machines running the same DGA and to detect active domain names that “look similar” to NXDomains resulting from the DGA and therefore probably point to the botnet C&C server's address.

> monitoring the DNS traffic in local networks

### Related Work

In the past, malware used IP fast-fluxing, where a single domain name pointed to several IP ad- dresses to avoid being taken down easily.

#### Villamarin-Salomon and Brustoloni 

Compared two approaches to identify botnet C&Cs

In their first approach, they identified domains with high query rates or domains that were temporally correlated. They used Chebyshev's inequality and Mahalanobis di=stance to identify anomalous domains. 

In their second approach, they analyzed recurring “dynamic” DNS replies with NXDomain responses.

First approach was ineffective, as several legitimate services use DNS with short time-to-live (TTL) values. However, their second approach yielded better detection and identified suspicious C&C domains.

### System Overview

Pleiades consists of two main modules: a DGA Discovery module, and a DGA Classification and C&C Detection module.

#### DGA Discovery

DGA Discovery module analyzes streams of unsuccessful DNS resolutions.All NXDomains generated by network users are collected during a given epoch (e.g., one day). 

##### Clustering Criteria

The collected NXDomains are clustered according to the following two similarity criteria:  

1. The domain name strings have similar statistical characteris- tics (e.g., similar length, similar level of “randomness”, similar character frequency distribution, etc.) and 
2. The domains have been queried by overlapping sets of hosts. 

> ==Main objective of this NXDomain clustering process is to group together domain names that likely are automatically generated by the same algorithm running on multiple machines within the monitored network==.

![Screenshot 2020-05-13 at 8.37.12 PM](/Users/vikramadityasingh/Library/Mobile Documents/com~apple~CloudDocs/Resarch/Images/Screenshot 2020-05-13 at 8.37.12 PM.png)

Because this clustering step is unsupervised, some of the output NXDomain clusters may contain groups of domains that happen to be similar by chance (e.g., NXDomains due to common typos or to mis- configured applications)

Use a supervised DGA Classifier to prune NXDomain clusters that appear to be generated by DGAs that we have previously discovered and mod- eled, or that contain domain names that are similar to popular legitimate domains. The final output of the DGA Discovery module is a set of NXDomain clusters, each of which likely represents the NXDomains generated by previously unknown or not yet modeled DGA-bots.

#### DGA Classification and C&C Detection

Every time a new DGA is discovered, we use a su- pervised learning approach to build models of what the domains generated by this new DGA “look like”.

1. A statistical multi-class classifier that focuses on assigning a specific DGA label to the set of NXDomains generated by a host $h_i$.
2. A Hidden Markov Model (HMM) that focuses on finding single active domain names queried by $h_i$ that are likely generated by a DGA

The DGA Modeling component receives different sets of domains labeled as Legitimate (i.e., “non-DGA”), DGA-Bobax, DGA-Torpig/Sinowal, DGA-Conficker.C, New-DGA-v1, New-DGA-v2, etc., and performs the training of the multi-class DGA Classifier and the HMM-based C&C Detection module.

##### DGA Classification

monitor the stream of NXDomains generated by each client machine, ==extract a number of statistical features related to the NXDomain strings==. 

Ask ==the DGA Classifier to identify whether this subset of NXDomains resembles the NXDomains generated by previously discovered DGAs==.

If the subset of NXDomains is assigned a specific DGA label (e.g., DGA-Conficker.C), the host that generated the NX- Domains is deemed to be compromised by the related DGA-bot.

we obtain the list of machines that appear to be compromised with DGA-based bots, Our goal is to iden- tify which domain names, among the ones generated by the discovered DGA-based bots, actually resolve into a valid IP address. In other words, we aim to identify the botnet's active C&C server.

we consider all domain names that are successfully resolved by hosts which have been classified as running a given DGA, say New-DGA-vX, by the DGA Classifier. Then, we test these successfully resolved domains against an HMM specifically trained to recognize domains generated by New-DGA-vX. The HMM analyzes the sequence of characters that compose a domain name d, and computes the likelihood that d is generated by New-DGA-vX.

We use an HMM, rather than the DGA Classifier, be- cause for the C&C detection phase we need to classify single domain names. The DGA Classifier is not suitable for this task because it expects as input sets of NXDo- mains generated by a given host to assign a label to the DGA-bot running on that host. Some of the features used by the DGA Classifier cannot be reliably extracted from a single domain name.

### DGA Discovery

Analyzes sequences of NXDomains generated by hosts in a monitored network, and in a completely unsupervised way, clusters NXDomains that are being automatically generated by a DGA. 

1. Split the overall set of NXDomains generated by all monitored hosts into small subsets, and ==translate each set into a statistical feature vector.==
2. Apply the X-means clustering algorithm to group these domain subsets into larger clusters of domain names that have similar string-based characteristics.
3. Cluster the NXDomains based on a completely different approach that takes into account whether two NXDomains are being queried by overlapping sets of hosts.



#### NXDomain Clustering

##### Statistical Features

###### Prequistes

splitting a sequence $N_X = {d_1 , d_2, ..., d_m}$ of NXDomains into a number of subsequences (or subsets) of length $\alpha$

$$
NX_k = {d_r, d_{r+1}, ..., d_{r+ −1}} \\ 
r = \alpha(k − 1) + 1 \\
k = 1, 2, ..., ⌊ m ⌋
$$
###### N - gram Features

measure the frequency distribution of n- grams across the domain name strings, with $n = 1, .., 4$. 

Compute the median, average and standard deviation of the obtained distribution of 2-gram frequency values, thus obtaining three features. We do this for each value of $n = 1,..,4$. producing 12 statistical features in total.

###### Entropy-based Features 
This group of features computes the entropy of the character distribution for separate domain levels.

1. extract the 2LD of each domain $d_i ∈ NX_k$ , and for each domain we compute the entropy $H(2LD(d_i))$ of the characters of its 2LD.
2. Compute the average and standard deviation of the set of values ${H (2LD(d_i))}_{i=1...\alpha}$.
3. Repeat this for 3LDs and for the overall domain name strings 

A total of six features, which capture the “level of randomness” in the domains. 

> The intuition is that most DGAs pro- duce random-looking domain name strings, and we want to account for this characteristic of the DGAs.

###### Structural Domain Features

This group of features is used to summarize information about the structure of the NXDomains in $NX_k$ such as their length, the number of unique TLDs, and the number of domain levels.    

##### Clustering using Statistical Features

Assuming $m$ is the number of distinct NXDomains in NX , we split the set NX into $⌊ m ⌋$ different subsets where $\alpha= 10$. 

After we have translated each NXk into its corresponding feature vector, we apply the X-means clustering algorithm.

At this point, given a cluster C = {NXk }k=1 ..l of l NXDomain subsets, we simply take the union of the NXk in C as an NXDomain cluster.

##### Clustering using Bipartite Graphs

Hosts that are compromised with the same DGA- based malware naturally tend to generate (with high probability) partially overlapping sets of NXDomains. 

“non-DGA”  NXDomains are unlikely to be queried by multiple hosts. For example, it is **unlikely that multiple distinct users make identical typos in a given epoch**.

to consider NXDomains that are queried by several common hosts as similar, and in turn use this similarity measure to cluster NXDomains that are likely generated by the same DGA.



build a sparse association matrix M, where columns represent NXDomains and rows represent hosts that query more than two of the column NX- Domains over the course of an epoch.

Discard those that query only one NXDomain to reduce the dimension- ality of the matrix, since they are extremely unlikely to be running a DGA given the low volume of NXDomains they produce.
$$
M_{ij} = 0 \ if\ host\ h_i\ did\ not\ query\ n_j \\
M_{ij} = w_i \ if\ host\ h_i\ did\ query\ n_j,\ and\ w_i\ is\ weight \\
$$
All non-zero entries related to a host $h_i$ are assigned the same weight $w_i ∼ \frac{1}{k}$ , , where $k_i$ is the number of NX-Domains queried by host $h_{i}$.

> The higher the number of unique NXDomains queried by a host hi (i.e., the higher ki) the less likely the host is “representative” of the NXDomains it queries.

M can be seen as a representation of a bipartite graph, in which a host vertex $V_{hi}$ is connected to an NXDomains vertex $V_{nj}$ with an edge of weight $w_i$ if host $h_i$ queried NXDomain $n_j$ during the epoch under consideration.

> mapping greatly reduces the dimensionality of the NXDomain vectors from the total number of hosts (the number of rows in M) to $\rho$.

Apply X- means to cluster the NXDomains based on their “host associations”. Namely, NXDomains are grouped together if they have been queried by a similar set of hosts.

##### Cluster Correlation

We com- pute the intersection between all possible pairs of clus- ters Ii, j = Ai ∩ B j , for i = 1, .., n and j = 1, .., m. All correlated clusters Ii, j that contain less than a predefined number of NXDomains (i.e., |Ii, j | < ) are discarded, while the remaining correlated clusters are passed to the DGA filtering module.

#### DGA Filtering

The DGA filtering module receives the NXDomain clusters from the clustering module.

This filtering step compares the newly discovered NXDomain clusters to domains generated by known DGAs that we have al- ready discovered and modeled.

 If the NXDomains in a correlated cluster Ii, j are classified as being generated by a known DGA, we discard the cluster Ii, j 

this filtering step is responsible for deter- mining if a cluster of NXDomains is too noisy, i.e., if it likely contains a mix of DGA and “non-DGA” domains.

> Treat the DGA Classifier as a function that takes as input a set NXk of NXDomains, and outputs a set of tuples {(lt , st )}t=1..c, where li is a label (e.g., DGA-Conficker.C), and si is a score that indicates how confident the classifier is on attributing label li to NXk , and c is the number of dif- ferent classes (and labels) that the DGA Classifier can recognize.

A new correlated cluster of NXDomains Ii, j , it splits the cluster into subsets of NXDomains, and then passes each of these subsets to the DGA Classifier.

Ii, j is divided into n different subsets. From the DGA Classifier, we obtain as a result n sets of tuples
{{(lt , st )}(1) t =1..c , {(lt , st )}(2) t =1..c , ..., {(lt , st )}(n)
t =1..c }.

consider for each set of tuples {(lt , st )}(k)
t =1..c
with k = 1, .., n, the label ˆ l(k) that was assigned the max-
imum score. We consider a cluster Ii, j as too noisy if the related labels ˆ
l(k) are too diverse.

cluster is too noisy when the majority label among the l(k), k = 1, ..n was assigned to less than ma j = 75% of ˆ
the n domain subsets. The clusters that do not pass the
ma j “purity” threshold will be discarded. Furthermore, NXDomain clusters whose majority label is the Legit- imate label will also be discarded.

each remaining cluster, we perform an additional “purity” check. Let the majority label for a given cluster
Ii, j be l∗. Among the set {{(lt , st )}(k) t =1..c }k=1..n we take all
the scores st whose related lt = l∗.

we take the confidence score assigned by the classifier to the domain subsets that have been labeled as l∗, and then we compute the average (st ) and the variance 2(st ) of these scores (notice that the scores st are in [0, 1]). We discard clusters whose 2(st ) is greater than a predefined threshold = 0.001, because we consider the domains in the cluster as not being sufficiently similar to the majority label class.

if (st ) < , with = 0.98, we deem the NXDomain cluster to be not similar enough to the majority label class, and instead we label it as “new DGA” and pass it to the DGA Modeling module. On the other hand, if (st ) ≥ , we confirm the majority label class (e.g., DGA-Conficker.C) and do not consider it further.



### DGA Classification and C&C Detection

#### DGA Modeling

the NXDomain clusters that pass the DGA Filtering and do not fit any known DGA model are (automatically) assigned a New-DGA- vX label, where X is a unique identifier. At this point, we build two different statical models representative of New-DGA-vX: 

1. A statistical multi-class classifier that can assign a specific DGA label to the set of NXDomains generated by a host hi and 
2. A Hidden Markov Model (HMM) that can compute the probability that a single active domain queried by hi was generated by the DGA running on the host, thus producing a list of candidate C&C domains.

DGA Modeling module takes as input the follow- ing information:  

1. A list of popular legitimate domain names extracted from the top 10,000 domains according to alexa.com; 
2. The list of NXDomains generated by running known DGA-bots in a controlled environment
3. The clusters of NXDomains re- ceived from the DGA Discovery module.

we identify all hosts that “contributed” to the NXDomains clustered in NX from our sparse asso- ciation matrix M and we gather all the NXDomains they generated during an epoch.

> the set
> NX ′hi may contain not only NXDomains generated by a
> host hi due to running a DGA, but it may also include NXDomains “accidentally' generated by hi. Therefore, this may introduce some noisy instances into the training dataset. However, the number of “accidental” NXDo- mains is typically very small, compared to the number of NXDomains generated by a DGA. Therefore, we rely on the generalization ability of the statistical learning algo- rithms we use to smooth away the effects of this potential source of noise.

#### DGA Classifier

The DGA Classifier is based on a multi-class version of the Alternating Decision Trees (ADT) learning algo- rithm [9]. ADT leverages the high classification accu- racy obtained by Boosting [17], while producing com- pact classification rules that can be more easily inter- preted.

monitor all NXDomains generated by each host in the monitored network and periodically send this information to the DGA Classifier. Given a set NXhi of NXDomains generated by host hi, we split NXhi into subsets of length , and from each of these subsets we extract a number of statistical features

 If one of these subsets of NXDomains is labeled by the DGA Classifier as being generated by a given DGA, we mark host hi as compromised and we add its IP address and the assigned DGA label to a malware detection report.



The C&C Detection module is based on Hidden Markov Models (HMM) [28]. We use one distinct HMM per DGA.

## Paper III - Stealthy Domain Generation Algorithms (DGAs)

CLEAN(CLassifier of bEnign domAin Names), for discovering benign domain names.

### INTRODUCTION 

when a malicious domain name has been detected and listed into blacklist, the user of it would abandon it and register some other ones to finish the same task as he has ever done. 

### CLEAN APPROACH

CLEAN consists of 3 parts as follows: 

1. Data Preprocessing, 
2. Stability Detection 
3. Naïve Bayesian Classifier

###### Passive DNS

Passive DNS traffic is a two-dimension dataset which consists of DNS requests and their related attributes including domain name, type, resolved IP address, timestamp, country/province, city, ISP and the like in every column.

### Data Preprocessing

> filter the NXDomains by the RCODE recorded in the passive DNS traffic. When the RCODE is 3, the domain name could be seen as NXDomain.

There are  also  **some request records which are completely incompatible with the domain naming rule in the passive DNS traffic**. It is obvious that these request records cannot be benign domain names.

### Stability Detection

The procedure of Stability Detection is detecting the domain names that appear every day from the selected domain names through the Data Preprocessing. 

1. The domain names which are CNAMEs of each other should be treated as the same domain names.
2. The domain names that shared the same resolving IP addresses should also be treated as the same domain names.

![Screenshot 2020-05-14 at 7.35.15 PM](/Users/vikramadityasingh/Library/Mobile Documents/com~apple~CloudDocs/Resarch/Images/Screenshot 2020-05-14 at 7.35.15 PM.png)

## Paper IV - Kindred Domains: Detecting and Clustering Botnet Domains Using DNS Traffic

Typical malware DNS lookup patterns when observed on a global scale and utilize this insight to engineer a system ca- pable of detecting and accurately clustering malware domains to a particular variant or malware family without the need for obtaining a malware sample.

### INTRODUCTION

Embedding the DGA instead of a list of previously-generated do- mains in the unobfuscated binary of the malware protects against a strings dump that could be fed into a network blacklisting appli- ance.

the fact that the DGA is pseudo random, DNS traffic lookup patterns will emerge as all infected hosts will request the same set of domain names in a given epoch of time.

We observe that NXDomains have a limited caching characteristic, which make most of the queries concerning NXDomains propagate to the registry DNS servers.

### DNS PROFILING OF DGA DOMAINS

DGAs provide the capability of generating pseudo-random domain names using a deterministic algorithm and some form of a seed, typically the date. The domains generated by the algorithm may vary in length and may be spread over multiple TLDs.

While, **infected computers will generate the same set of domains at that particular period of time and attempt to connect to those domain names**, only the domain previously registered by the malware author will resolve and serve as the C2 server while the remaining domains will fail to resolve.

NXDomain is a commonly used term for a domain name that is unable to resolve because the domain name is not registered or a name server problem occurred during resolution. The term was originally used to represent DNS response code 3.



The large volume of NXDomain requests and low re-occurrence of unique second-level domains suggests an extremely high rate of entropy within the NXDomain DNS traffic ecosphere.

### Conficker NXDomain DNS

## Paper - V Detecting the DGA-Based Malicious Domain Names



## Paper - VI Detecting Algorithmically Generated Domains Using Data Visualization and N-Grams Methods

### Abstract

Employing domain generation algorithms (DGA) to dynamically produce a large number of random domains and select a small subset for actual use so that static domain lists ineffective. 

### INTRODUCTION

Botnet detection systems use a blacklist of command-and-control (C&C) domains to detect bots and block there traffic.

DGA is to be deterministic, yet generate a huge number of random domains so that bot maintainer only has to register one or few to enable the malware to work.



The purpose of building a DGA classifier is not to take down botnets, but to discover and detect the use on our network or services.

### BACKGROUND

---------------------

## Paper VII - A  Method for Detecting DGA Botnet Based on Semantic and Cluster Analysis

###  PROPOSED DGA DETECTION METHOD

our system has three stages: 

1. Domain filtering, 
2. DGA filtering 
3. DGA clustering

Goal  of  our  method  is  that  **analyze NXDomain which is generated by DGA botnet, so all benign domains have  to  be  removed  from  the  collection**.

NXDomains are clustered in DGA Clustering module based on K-means  algorithm.  In  this  module,  NXDomains  are  clustered  into different clusters. Each cluster corresponds to a type of DGA botnet. 

#### Domain Filtering

In Domain Filter module, we design a filter to filter out normal domains. The  module uses two techniques to filter out normal domain. It consists filter based on White-list dataset that contains normal domain already known and based on semantic features of the domain.

##### Filter based White-list dataset



##### Features Extraction

